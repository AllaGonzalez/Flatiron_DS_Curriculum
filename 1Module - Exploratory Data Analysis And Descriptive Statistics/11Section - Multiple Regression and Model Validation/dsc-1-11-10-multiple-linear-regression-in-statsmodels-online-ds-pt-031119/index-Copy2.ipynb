{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression in Statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lecture, you'll learn how to run your first multiple linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "You will be able to:\n",
    "* Introduce Statsmodels for multiple regression\n",
    "* Present alternatives for running regression in Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statsmodels for multiple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lecture will be more of a code-along, where we will walk through a multiple linear regression model using both Statsmodels and Scikit-Learn. \n",
    "\n",
    "Remember that we introduced single linear regression before, which is known as ordinary least squares. It determines a line of best fit by minimizing the sum of squares of the errors between the models predictions and the actual data. In algebra and statistics classes, this is often limited to the simple 2 variable case of $y=mx+b$, but this process can be generalized to use multiple predictive variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto-mpg data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below reiterates the steps we've taken before: we've created dummies for our categorical variables and have log-transformed some of our continuous predictors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv(\"auto-mpg.csv\") \n",
    "data['horsepower'].astype(str).astype(int)\n",
    "\n",
    "acc = data[\"acceleration\"]\n",
    "logdisp = np.log(data[\"displacement\"])\n",
    "loghorse = np.log(data[\"horsepower\"])\n",
    "logweight= np.log(data[\"weight\"])\n",
    "\n",
    "scaled_acc = (acc-min(acc))/(max(acc)-min(acc))\t\n",
    "scaled_disp = (logdisp-np.mean(logdisp))/np.sqrt(np.var(logdisp))\n",
    "scaled_horse = (loghorse-np.mean(loghorse))/(max(loghorse)-min(loghorse))\n",
    "scaled_weight= (logweight-np.mean(logweight))/np.sqrt(np.var(logweight))\n",
    "\n",
    "data_fin = pd.DataFrame([])\n",
    "data_fin[\"acc\"]= scaled_acc\n",
    "data_fin[\"disp\"]= scaled_disp\n",
    "data_fin[\"horse\"] = scaled_horse\n",
    "data_fin[\"weight\"] = scaled_weight\n",
    "cyl_dummies = pd.get_dummies(data[\"cylinders\"], prefix=\"cyl\")\n",
    "yr_dummies = pd.get_dummies(data[\"model year\"], prefix=\"yr\")\n",
    "orig_dummies = pd.get_dummies(data[\"origin\"], prefix=\"orig\")\n",
    "mpg = data[\"mpg\"]\n",
    "data_fin = pd.concat([mpg, data_fin, cyl_dummies, yr_dummies, orig_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 392 entries, 0 to 391\n",
      "Data columns (total 26 columns):\n",
      "mpg       392 non-null float64\n",
      "acc       392 non-null float64\n",
      "disp      392 non-null float64\n",
      "horse     392 non-null float64\n",
      "weight    392 non-null float64\n",
      "cyl_3     392 non-null uint8\n",
      "cyl_4     392 non-null uint8\n",
      "cyl_5     392 non-null uint8\n",
      "cyl_6     392 non-null uint8\n",
      "cyl_8     392 non-null uint8\n",
      "yr_70     392 non-null uint8\n",
      "yr_71     392 non-null uint8\n",
      "yr_72     392 non-null uint8\n",
      "yr_73     392 non-null uint8\n",
      "yr_74     392 non-null uint8\n",
      "yr_75     392 non-null uint8\n",
      "yr_76     392 non-null uint8\n",
      "yr_77     392 non-null uint8\n",
      "yr_78     392 non-null uint8\n",
      "yr_79     392 non-null uint8\n",
      "yr_80     392 non-null uint8\n",
      "yr_81     392 non-null uint8\n",
      "yr_82     392 non-null uint8\n",
      "orig_1    392 non-null uint8\n",
      "orig_2    392 non-null uint8\n",
      "orig_3    392 non-null uint8\n",
      "dtypes: float64(5), uint8(21)\n",
      "memory usage: 23.4 KB\n"
     ]
    }
   ],
   "source": [
    "data_fin.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was the data we had until now. As we want to focus on model interpretation and still don't want to have a massive model for now, let's only inlude \"acc\", \"horse\" and the three \"orig\" categories in our final data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>weight</th>\n",
       "      <th>orig_1</th>\n",
       "      <th>orig_2</th>\n",
       "      <th>orig_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.720986</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.908047</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.651205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.648095</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.148810</td>\n",
       "      <td>0.664652</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  acceleration    weight  orig_1  orig_2  orig_3\n",
       "0  18.0      0.238095  0.720986       1       0       0\n",
       "1  15.0      0.208333  0.908047       1       0       0\n",
       "2  18.0      0.178571  0.651205       1       0       0\n",
       "3  16.0      0.238095  0.648095       1       0       0\n",
       "4  17.0      0.148810  0.664652       1       0       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ols = pd.concat([mpg, scaled_acc, scaled_weight, orig_dummies], axis= 1)\n",
    "data_ols.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use the statsmodels.api to run our ols on all our data. Just like for linear regression with a single predictor, you can use the formula $y \\sim X$, where, with $n$ predictors, X is represented as $x_1+\\ldots+x_n$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lore.dirick/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"mpg ~ acceleration+weight+orig_1+orig_2+orig_3\"\n",
    "model = ols(formula= formula, data=data_ols).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having to type out all the predictors isn't practical when you have many. Another better way than to type them all out is to seperate out the outcome variable \"mpg\" out of your data frame, and use the a `\"+\".join()` command on the predictors, as done below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = 'mpg'\n",
    "predictors = data_ols.drop('mpg', axis=1)\n",
    "pred_sum = \"+\".join(predictors.columns)\n",
    "formula = outcome + \"~\" + pred_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.726</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.723</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   256.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 14 Oct 2018</td> <th>  Prob (F-statistic):</th> <td>1.86e-107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:01:49</td>     <th>  Log-Likelihood:    </th> <td> -1107.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   392</td>      <th>  AIC:               </th> <td>   2224.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   387</td>      <th>  BIC:               </th> <td>   2244.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>   16.1041</td> <td>    0.509</td> <td>   31.636</td> <td> 0.000</td> <td>   15.103</td> <td>   17.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acceleration</th> <td>    5.0494</td> <td>    1.389</td> <td>    3.634</td> <td> 0.000</td> <td>    2.318</td> <td>    7.781</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weight</th>       <td>   -5.8764</td> <td>    0.282</td> <td>  -20.831</td> <td> 0.000</td> <td>   -6.431</td> <td>   -5.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>orig_1</th>       <td>    4.6566</td> <td>    0.363</td> <td>   12.839</td> <td> 0.000</td> <td>    3.944</td> <td>    5.370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>orig_2</th>       <td>    5.0690</td> <td>    0.454</td> <td>   11.176</td> <td> 0.000</td> <td>    4.177</td> <td>    5.961</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>orig_3</th>       <td>    6.3785</td> <td>    0.430</td> <td>   14.829</td> <td> 0.000</td> <td>    5.533</td> <td>    7.224</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>37.427</td> <th>  Durbin-Watson:     </th> <td>   0.840</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  55.989</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.648</td> <th>  Prob(JB):          </th> <td>6.95e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.322</td> <th>  Cond. No.          </th> <td>2.18e+15</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.726\n",
       "Model:                            OLS   Adj. R-squared:                  0.723\n",
       "Method:                 Least Squares   F-statistic:                     256.7\n",
       "Date:                Sun, 14 Oct 2018   Prob (F-statistic):          1.86e-107\n",
       "Time:                        18:01:49   Log-Likelihood:                -1107.2\n",
       "No. Observations:                 392   AIC:                             2224.\n",
       "Df Residuals:                     387   BIC:                             2244.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept       16.1041      0.509     31.636      0.000      15.103      17.105\n",
       "acceleration     5.0494      1.389      3.634      0.000       2.318       7.781\n",
       "weight          -5.8764      0.282    -20.831      0.000      -6.431      -5.322\n",
       "orig_1           4.6566      0.363     12.839      0.000       3.944       5.370\n",
       "orig_2           5.0690      0.454     11.176      0.000       4.177       5.961\n",
       "orig_3           6.3785      0.430     14.829      0.000       5.533       7.224\n",
       "==============================================================================\n",
       "Omnibus:                       37.427   Durbin-Watson:                   0.840\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               55.989\n",
       "Skew:                           0.648   Prob(JB):                     6.95e-13\n",
       "Kurtosis:                       4.322   Cond. No.                     2.18e+15\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.41e-28. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ols(formula= formula, data=data_ols).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or even easier, simply use the `.OLS`-method from statsmodels.api. The advantage is that you don't have to create the summation string. Important to note, however, is that the intercept term is not included by default, so you have to make sure you manipulate your `predictors` dataframe so it inclused a constant term. You can do this using `.add_constant`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.726</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.723</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   256.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 14 Oct 2018</td> <th>  Prob (F-statistic):</th> <td>1.86e-107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:01:49</td>     <th>  Log-Likelihood:    </th> <td> -1107.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   392</td>      <th>  AIC:               </th> <td>   2224.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   387</td>      <th>  BIC:               </th> <td>   2244.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>        <td>   16.1041</td> <td>    0.509</td> <td>   31.636</td> <td> 0.000</td> <td>   15.103</td> <td>   17.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acceleration</th> <td>    5.0494</td> <td>    1.389</td> <td>    3.634</td> <td> 0.000</td> <td>    2.318</td> <td>    7.781</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weight</th>       <td>   -5.8764</td> <td>    0.282</td> <td>  -20.831</td> <td> 0.000</td> <td>   -6.431</td> <td>   -5.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>orig_1</th>       <td>    4.6566</td> <td>    0.363</td> <td>   12.839</td> <td> 0.000</td> <td>    3.944</td> <td>    5.370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>orig_2</th>       <td>    5.0690</td> <td>    0.454</td> <td>   11.176</td> <td> 0.000</td> <td>    4.177</td> <td>    5.961</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>orig_3</th>       <td>    6.3785</td> <td>    0.430</td> <td>   14.829</td> <td> 0.000</td> <td>    5.533</td> <td>    7.224</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>37.427</td> <th>  Durbin-Watson:     </th> <td>   0.840</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  55.989</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.648</td> <th>  Prob(JB):          </th> <td>6.95e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.322</td> <th>  Cond. No.          </th> <td>2.18e+15</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.726\n",
       "Model:                            OLS   Adj. R-squared:                  0.723\n",
       "Method:                 Least Squares   F-statistic:                     256.7\n",
       "Date:                Sun, 14 Oct 2018   Prob (F-statistic):          1.86e-107\n",
       "Time:                        18:01:49   Log-Likelihood:                -1107.2\n",
       "No. Observations:                 392   AIC:                             2224.\n",
       "Df Residuals:                     387   BIC:                             2244.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "const           16.1041      0.509     31.636      0.000      15.103      17.105\n",
       "acceleration     5.0494      1.389      3.634      0.000       2.318       7.781\n",
       "weight          -5.8764      0.282    -20.831      0.000      -6.431      -5.322\n",
       "orig_1           4.6566      0.363     12.839      0.000       3.944       5.370\n",
       "orig_2           5.0690      0.454     11.176      0.000       4.177       5.961\n",
       "orig_3           6.3785      0.430     14.829      0.000       5.533       7.224\n",
       "==============================================================================\n",
       "Omnibus:                       37.427   Durbin-Watson:                   0.840\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               55.989\n",
       "Skew:                           0.648   Prob(JB):                     6.95e-13\n",
       "Kurtosis:                       4.322   Cond. No.                     2.18e+15\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.41e-28. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "predictors_int = sm.add_constant(predictors)\n",
    "model = sm.OLS(data['mpg'],predictors_int).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like for single multiple regression, the coefficients for our model should be interpreted as \"how does Y change for each additional unit X\"? Do note that the fact that we transformed X, interpretation can sometimes require a little more attention. In fact, as the model is built on the transformed X, the actual relationship is \"how does Y change for each additional unit X'\", where X' is the (log- and min-max, standardized,...) transformed data matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using scikit learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also repeat this process using Scikit-Learn. The code to do this can be found below. Scikit-learn is very popular "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data_ols['mpg']\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(predictors, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.04941007, -5.87640551, -0.71140721, -0.29903267,  1.01043987])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coefficients\n",
    "linreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.4721642860754"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intercept\n",
    "linreg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why are the coefficients diff?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = predictors.drop(\"orig_3\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.04941007, -5.87640551, -1.72184708, -1.30947254])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.fit(predictors, y)\n",
    "linreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.48260416045567"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.726</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.723</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   256.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 14 Oct 2018</td> <th>  Prob (F-statistic):</th> <td>1.86e-107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:01:49</td>     <th>  Log-Likelihood:    </th> <td> -1107.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   392</td>      <th>  AIC:               </th> <td>   2224.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   387</td>      <th>  BIC:               </th> <td>   2244.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>   22.4826</td> <td>    0.789</td> <td>   28.504</td> <td> 0.000</td> <td>   20.932</td> <td>   24.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acceleration</th> <td>    5.0494</td> <td>    1.389</td> <td>    3.634</td> <td> 0.000</td> <td>    2.318</td> <td>    7.781</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weight</th>       <td>   -5.8764</td> <td>    0.282</td> <td>  -20.831</td> <td> 0.000</td> <td>   -6.431</td> <td>   -5.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>orig_1</th>       <td>   -1.7218</td> <td>    0.653</td> <td>   -2.638</td> <td> 0.009</td> <td>   -3.005</td> <td>   -0.438</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>orig_2</th>       <td>   -1.3095</td> <td>    0.688</td> <td>   -1.903</td> <td> 0.058</td> <td>   -2.662</td> <td>    0.043</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>37.427</td> <th>  Durbin-Watson:     </th> <td>   0.840</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  55.989</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.648</td> <th>  Prob(JB):          </th> <td>6.95e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.322</td> <th>  Cond. No.          </th> <td>    9.59</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.726\n",
       "Model:                            OLS   Adj. R-squared:                  0.723\n",
       "Method:                 Least Squares   F-statistic:                     256.7\n",
       "Date:                Sun, 14 Oct 2018   Prob (F-statistic):          1.86e-107\n",
       "Time:                        18:01:49   Log-Likelihood:                -1107.2\n",
       "No. Observations:                 392   AIC:                             2224.\n",
       "Df Residuals:                     387   BIC:                             2244.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept       22.4826      0.789     28.504      0.000      20.932      24.033\n",
       "acceleration     5.0494      1.389      3.634      0.000       2.318       7.781\n",
       "weight          -5.8764      0.282    -20.831      0.000      -6.431      -5.322\n",
       "orig_1          -1.7218      0.653     -2.638      0.009      -3.005      -0.438\n",
       "orig_2          -1.3095      0.688     -1.903      0.058      -2.662       0.043\n",
       "==============================================================================\n",
       "Omnibus:                       37.427   Durbin-Watson:                   0.840\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               55.989\n",
       "Skew:                           0.648   Prob(JB):                     6.95e-13\n",
       "Kurtosis:                       4.322   Cond. No.                         9.59\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_sum = \"+\".join(predictors.columns)\n",
    "formula = outcome + \"~\" + pred_sum\n",
    "model = ols(formula= formula, data=data_ols).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## forward selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  LSTAT                          with p-value 5.0811e-88\n",
      "Add  RM                             with p-value 3.47226e-27\n",
      "Add  PTRATIO                        with p-value 1.64466e-14\n",
      "Add  DIS                            with p-value 1.66847e-05\n",
      "Add  NOX                            with p-value 5.48815e-08\n",
      "Add  CHAS                           with p-value 0.000265473\n",
      "Add  B                              with p-value 0.000771946\n",
      "Add  ZN                             with p-value 0.00465162\n",
      "resulting features:\n",
      "['LSTAT', 'RM', 'PTRATIO', 'DIS', 'NOX', 'CHAS', 'B', 'ZN']\n"
     ]
    }
   ],
   "source": [
    "### \n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "data = load_boston()\n",
    "boston_pred = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "boston_target = data.target\n",
    "\n",
    "\n",
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \"\"\" Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included\n",
    "\n",
    "result = stepwise_selection(boston_pred,boston_target)\n",
    "\n",
    "print('resulting features:')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://datascience.stackexchange.com/questions/937/does-scikit-learn-have-forward-selection-stepwise-regression-algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  weight                         with p-value 1.16293e-107\n",
      "Add  acceleration                   with p-value 0.000646572\n"
     ]
    }
   ],
   "source": [
    "result = stepwise_selection(predictors, y, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acceleration</th>\n",
       "      <th>weight</th>\n",
       "      <th>orig_1</th>\n",
       "      <th>orig_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.720986</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.908047</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.651205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.648095</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.148810</td>\n",
       "      <td>0.664652</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.119048</td>\n",
       "      <td>1.483701</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.059524</td>\n",
       "      <td>1.494349</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.029762</td>\n",
       "      <td>1.459834</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.119048</td>\n",
       "      <td>1.551945</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.029762</td>\n",
       "      <td>1.056296</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.780443</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.826120</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.089286</td>\n",
       "      <td>0.973016</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.268664</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>-0.668325</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.446429</td>\n",
       "      <td>-0.035923</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.446429</td>\n",
       "      <td>-0.110862</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.476190</td>\n",
       "      <td>-0.359373</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.386905</td>\n",
       "      <td>-1.051504</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.744048</td>\n",
       "      <td>-1.582335</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.565476</td>\n",
       "      <td>-0.244259</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.386905</td>\n",
       "      <td>-0.582305</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.565476</td>\n",
       "      <td>-0.663824</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.267857</td>\n",
       "      <td>-0.881756</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>-0.276387</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.357143</td>\n",
       "      <td>1.701646</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>1.512295</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.327381</td>\n",
       "      <td>1.517174</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.790793</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.386905</td>\n",
       "      <td>-1.051504</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>0.690476</td>\n",
       "      <td>-0.334684</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>0.630952</td>\n",
       "      <td>-0.287161</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>0.595238</td>\n",
       "      <td>-0.633964</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>0.488095</td>\n",
       "      <td>-0.375929</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>0.476190</td>\n",
       "      <td>-0.445750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>0.595238</td>\n",
       "      <td>-0.161279</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.004072</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>0.434524</td>\n",
       "      <td>-1.311530</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>0.607143</td>\n",
       "      <td>-1.231509</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>-1.329559</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>0.398810</td>\n",
       "      <td>-1.059873</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>0.553571</td>\n",
       "      <td>-1.059873</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>0.386905</td>\n",
       "      <td>-1.001703</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>0.386905</td>\n",
       "      <td>-0.928282</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>0.529762</td>\n",
       "      <td>-0.864267</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>-1.338608</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>0.458333</td>\n",
       "      <td>-1.338608</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0.488095</td>\n",
       "      <td>-1.284656</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.102138</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.185784</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0.386905</td>\n",
       "      <td>-0.362127</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>0.398810</td>\n",
       "      <td>-0.033410</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>0.351190</td>\n",
       "      <td>-0.253600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0.297619</td>\n",
       "      <td>-0.671328</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>0.553571</td>\n",
       "      <td>0.108178</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0.452381</td>\n",
       "      <td>-0.090383</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0.988095</td>\n",
       "      <td>-1.051504</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0.214286</td>\n",
       "      <td>-0.785832</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>0.630952</td>\n",
       "      <td>-0.307450</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>0.678571</td>\n",
       "      <td>-0.180861</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     acceleration    weight  orig_1  orig_2\n",
       "0        0.238095  0.720986       1       0\n",
       "1        0.208333  0.908047       1       0\n",
       "2        0.178571  0.651205       1       0\n",
       "3        0.238095  0.648095       1       0\n",
       "4        0.148810  0.664652       1       0\n",
       "5        0.119048  1.483701       1       0\n",
       "6        0.059524  1.494349       1       0\n",
       "7        0.029762  1.459834       1       0\n",
       "8        0.119048  1.551945       1       0\n",
       "9        0.029762  1.056296       1       0\n",
       "10       0.119048  0.780443       1       0\n",
       "11       0.000000  0.826120       1       0\n",
       "12       0.089286  0.973016       1       0\n",
       "13       0.119048  0.268664       1       0\n",
       "14       0.416667 -0.668325       0       0\n",
       "15       0.446429 -0.035923       1       0\n",
       "16       0.446429 -0.110862       1       0\n",
       "17       0.476190 -0.359373       1       0\n",
       "18       0.386905 -1.051504       0       0\n",
       "19       0.744048 -1.582335       0       1\n",
       "20       0.565476 -0.244259       0       1\n",
       "21       0.386905 -0.582305       0       1\n",
       "22       0.565476 -0.663824       0       1\n",
       "23       0.267857 -0.881756       0       1\n",
       "24       0.416667 -0.276387       1       0\n",
       "25       0.357143  1.701646       1       0\n",
       "26       0.416667  1.512295       1       0\n",
       "27       0.327381  1.517174       1       0\n",
       "28       0.625000  1.790793       1       0\n",
       "29       0.386905 -1.051504       0       0\n",
       "..            ...       ...     ...     ...\n",
       "362      0.690476 -0.334684       1       0\n",
       "363      0.630952 -0.287161       1       0\n",
       "364      0.595238 -0.633964       1       0\n",
       "365      0.488095 -0.375929       1       0\n",
       "366      0.476190 -0.445750       1       0\n",
       "367      0.595238 -0.161279       1       0\n",
       "368      0.500000  0.004072       1       0\n",
       "369      0.434524 -1.311530       0       1\n",
       "370      0.607143 -1.231509       0       0\n",
       "371      0.571429 -1.329559       0       0\n",
       "372      0.398810 -1.059873       1       0\n",
       "373      0.553571 -1.059873       1       0\n",
       "374      0.386905 -1.001703       0       0\n",
       "375      0.386905 -0.928282       0       0\n",
       "376      0.529762 -0.864267       0       0\n",
       "377      0.416667 -1.338608       0       0\n",
       "378      0.458333 -1.338608       0       0\n",
       "379      0.488095 -1.284656       0       0\n",
       "380      0.500000  0.102138       1       0\n",
       "381      0.535714  0.185784       1       0\n",
       "382      0.386905 -0.362127       1       0\n",
       "383      0.398810 -0.033410       1       0\n",
       "384      0.351190 -0.253600       0       0\n",
       "385      0.297619 -0.671328       1       0\n",
       "386      0.553571  0.108178       1       0\n",
       "387      0.452381 -0.090383       1       0\n",
       "388      0.988095 -1.051504       0       1\n",
       "389      0.214286 -0.785832       1       0\n",
       "390      0.630952 -0.307450       1       0\n",
       "391      0.678571 -0.180861       1       0\n",
       "\n",
       "[392 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
