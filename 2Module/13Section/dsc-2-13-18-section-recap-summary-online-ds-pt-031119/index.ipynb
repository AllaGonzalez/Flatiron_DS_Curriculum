{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This short lesson summarizes the topics we covered in section 13 and why they'll be important to you as a data scientist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "You will be able to:\n",
    "* Understand and explain what was covered in this section\n",
    "* Understand and explain why this section will help you become a data scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "The goal of section 13 was to provide both a conceptual and computational introduction to Linear Algebra - one of the foundational concepts underlying most machine learning models. Some of the key takeaways include:\n",
    "* Understanding Linear Algebra will provide you a much stronger foundation when learning a range of data science topics - from Support Vector Machines and deep learning through Natural Language Processing and dimensionality reduction techniques like Principle Component Analysis\n",
    "* One use case for vectors and matrices is for representing and solving systems of linear equations\n",
    "* A scalar is a single, real number. A vector is a one dimensional array of numbers. A matrix is a 2 dimsional array of numbers. \n",
    "* A tensor is a generalized term for an n-dimensional rectangular grid of numbers. A vector is a one-dimensional (first order) tensor, a matrix is a two-dimensional (second order tensor), etc.\n",
    "* Two matrices can be added together if they have the same shape\n",
    "* Scalars can be added to matrices by adding the scalar (number) to each element\n",
    "* Broadcasting allows for the additiona of matrices of different shapes by extending the dimensions of the smaller matrix to match the dimensions of the larger one\n",
    "* To calculate the dot product for matrix multiplication, the first matrix must have the same number of columns and the second has rows.\n",
    "* Matrix multiplication is distributive and associative, but not commutative\n",
    "* Operating on NumPy data types is substantially more computationally efficient than performing the same operations on native Python data types\n",
    "* It is possible to use Linear Algebra in NumPy to solve for a linear regression using the OLS method\n",
    "* OLS is not computationally efficient, so in practice we usually perform a gradient descent imstead to solve a linear regression\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
