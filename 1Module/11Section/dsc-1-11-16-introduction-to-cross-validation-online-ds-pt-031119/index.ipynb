{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You learned about train-test-split before, but also noticed that running the model with a different split for train and test can lead to significantly different results. This is one of the many reasons why you'll want to consider cross-valisation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "- Explain the superiority of cross-validation over simple validation testing\n",
    "- Understand and implement k-fold cross validation in Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The problem with train-test-split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using train-test-split, random samples of the data are created for the training and the test set. The problem with this is that the training and test MSE strongly depend on how the training and test sets were created. Let's see how this happens in practice using the auto-mpg data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's copy our pre-processed auto-mpg data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv(\"auto-mpg.csv\") \n",
    "data['horsepower'].astype(str).astype(int)\n",
    "\n",
    "acc = data[\"acceleration\"]\n",
    "logdisp = np.log(data[\"displacement\"])\n",
    "loghorse = np.log(data[\"horsepower\"])\n",
    "logweight= np.log(data[\"weight\"])\n",
    "\n",
    "scaled_acc = (acc-min(acc))/(max(acc)-min(acc))\t\n",
    "scaled_disp = (logdisp-np.mean(logdisp))/np.sqrt(np.var(logdisp))\n",
    "scaled_horse = (loghorse-np.mean(loghorse))/(max(loghorse)-min(loghorse))\n",
    "scaled_weight= (logweight-np.mean(logweight))/np.sqrt(np.var(logweight))\n",
    "\n",
    "data_fin = pd.DataFrame([])\n",
    "data_fin[\"acc\"]= scaled_acc\n",
    "data_fin[\"disp\"]= scaled_disp\n",
    "data_fin[\"horse\"] = scaled_horse\n",
    "data_fin[\"weight\"] = scaled_weight\n",
    "cyl_dummies = pd.get_dummies(data[\"cylinders\"], prefix=\"cyl\")\n",
    "yr_dummies = pd.get_dummies(data[\"model year\"], prefix=\"yr\")\n",
    "orig_dummies = pd.get_dummies(data[\"origin\"], prefix=\"orig\")\n",
    "mpg = data[\"mpg\"]\n",
    "data_fin = pd.concat([mpg, data_fin, cyl_dummies, yr_dummies, orig_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([mpg, scaled_acc, scaled_weight, orig_dummies], axis= 1)\n",
    "y = data[[\"mpg\"]]\n",
    "X = data.drop([\"mpg\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below repeats a train-test-split creation 20 times, using a test_size of 0.33. So what happens is, each time a new (random) train-test-split is created. See how training and testing MSEs swing around by just taking another sample!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num = 20\n",
    "train_err = []\n",
    "test_err = []\n",
    "for i in range(num):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "    linreg.fit(X_train, y_train)\n",
    "    y_hat_train = linreg.predict(X_train)\n",
    "    y_hat_test = linreg.predict(X_test)\n",
    "    train_err.append(mean_squared_error(y_train, y_hat_train))\n",
    "    test_err.append(mean_squared_error(y_test, y_hat_test))\n",
    "plt.scatter(list(range(num)), train_err, label='Training Error')\n",
    "plt.scatter(list(range(num)), test_err, label='Testing Error')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to deal with the issues that random sampling can introduce into interpreting the quality of our models, we'll use a more advanced technique called **K-Fold Cross Validation**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Fold Cross Validation expands on the idea of training and testing splits by splitting the entire dataset into {K} equal sections of data. We'll then iteratively train {K} linear regression models on the data, with each linear model using a different section of data as the testing set, and all other sections combined as the training set.\n",
    "\n",
    "We can then average the individual results frome each of these linear models to get a Cross-Validation MSE. This will be closer to the model's actual MSE, since \"noisy\" results that are higher than average will cancel out the \"noisy\" results that are lower than average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='cross-val-graphic.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can easily do this in scikit-learn using `cross_val_score`. If you want the mean squared error as an output, you need to specify `scoring` and pass \"neg_mean_squared_error\". Note that this negates your mean squared error, so larger means better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_5_results = np.mean(cross_val_score(linreg, X, y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "cv_10_results = np.mean(cross_val_score(linreg, X, y, cv=10, scoring=\"neg_mean_squared_error\"))\n",
    "cv_20_results = np.mean(cross_val_score(linreg, X, y, cv=20, scoring=\"neg_mean_squared_error\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to perform Cross-validations, and we strongly recommend you have a look at the [Cross-validation documentation in Scikit-Learn](http://scikit-learn.org/stable/modules/cross_validation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "Great! Now let's put this into practice on our Boston Housing Data!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
